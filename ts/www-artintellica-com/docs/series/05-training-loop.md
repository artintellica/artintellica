+++
title = "Learn the Training Loop with PyTorch"
icon = "training-loop"
author = "Artintellica"
date = "2025-06-18"
+++

**Module 1: The Elementary Training Loop**

1. [Introduction: What is a Training Loop?](/blog/0096-training-loop-11.md)
2. [The Simplest Case: Linear Regression](/blog/0097-training-loop-12.md)
3. [Batch vs. Stochastic Gradient Descent](/blog/0098-training-loop-13.md)
4. [Visualizing the Loss Landscape](/blog/0099-training-loop-14.md)
5. [Numerical vs. Analytical Gradients](/blog/0100-training-loop-15.md)
6. [Recap and Key Takeaways](/blog/0101-training-loop-16.md)

**Module 2: The Training Loop for Neural Networks**

1. [From Linear to Nonlinear: Why Neural Networks?](/blog/0102-training-loop-21.md)
2. [Forward and Backward Passes](/blog/0103-training-loop-22.md)
3. [Implementing a Simple Neural Net from Scratch](/blog/0104-training-loop-23.md)
4. [The Role of Activations](/blog/0105-training-loop-24.md)
5. [Mini-batching and Data Pipelines](/blog/0106-training-loop-25.md)
6. [Regularization and Overfitting](/blog/0107-training-loop-26.md)
7. [Recap: Comparing Our Simple Network with Linear Regression](/blog/0108-training-loop-27.md)

**Module 3: Advanced Training Loops and Modern Tricks**

1. [Optimization Algorithms Beyond SGD](/blog/0109-training-loop-31.md)
2. [Learning Rate Scheduling](/blog/0110-training-loop-32.md)
3. [Weight Initialization](/blog/0111-training-loop-33.md)
4. [Deeper Networks and Backprop Challenges](/blog/0112-training-loop-34.md)
5. [Large-Scale Training: Data Parallelism and Hardware](/blog/0113-training-loop-35.md)
6. [Monitoring and Debugging the Training Loop](/blog/0114-training-loop-36.md)
7. [Modern Regularization and Generalization Techniques](/blog/0115-training-loop-37.md)
8. [The Training Loop in Practice: Case Studies](/blog/0116-training-loop-38.md)
9. [Conclusion: What's Next After the Training Loop?](/blog/0117-training-loop-39.md)

