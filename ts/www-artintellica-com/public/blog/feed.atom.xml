<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://artintellica.com/blog</id>
    <title>Artintellica Blog</title>
    <updated>2025-06-16T22:05:07.193Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <author>
        <name>Ryan X. Charles</name>
        <email>artintellica@ryanxcharles.com</email>
        <uri>https://artintellica.com</uri>
    </author>
    <link rel="alternate" href="https://artintellica.com/blog"/>
    <link rel="self" href="https://example.com/blog/feed.atom.xml"/>
    <subtitle>Artintellica Blog</subtitle>
    <icon>https://artintellica.com/favicon.ico</icon>
    <rights>Copyright (C) 2025 Ryan X. Charles</rights>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.4: The Role of Activations]]></title>
        <id>https://artintellica.com/blog/0105-training-loop-24.md</id>
        <link href="https://artintellica.com/blog/0105-training-loop-24.md"/>
        <updated>2025-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.4: The Role of Activations]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.3: Implementing a Simple Neural Net from Scratch]]></title>
        <id>https://artintellica.com/blog/0104-training-loop-23.md</id>
        <link href="https://artintellica.com/blog/0104-training-loop-23.md"/>
        <updated>2025-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.3: Implementing a Simple Neural Net from Scratch]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.2: Forward and Backward Passes]]></title>
        <id>https://artintellica.com/blog/0103-training-loop-22.md</id>
        <link href="https://artintellica.com/blog/0103-training-loop-22.md"/>
        <updated>2025-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.2: Forward and Backward Passes]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.1: From Linear to Nonlinear: Why Neural Networks?]]></title>
        <id>https://artintellica.com/blog/0102-training-loop-21.md</id>
        <link href="https://artintellica.com/blog/0102-training-loop-21.md"/>
        <updated>2025-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 2.1: From Linear to Nonlinear: Why Neural Networks?]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.6: Recap and Key Takeaways]]></title>
        <id>https://artintellica.com/blog/0101-training-loop-16.md</id>
        <link href="https://artintellica.com/blog/0101-training-loop-16.md"/>
        <updated>2025-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.6: Recap and Key Takeaways]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.5: Numerical vs. Analytical Gradients]]></title>
        <id>https://artintellica.com/blog/0100-training-loop-15.md</id>
        <link href="https://artintellica.com/blog/0100-training-loop-15.md"/>
        <updated>2025-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.5: Numerical vs. Analytical Gradients]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.4: Visualizing the Loss Landscape]]></title>
        <id>https://artintellica.com/blog/0099-training-loop-14.md</id>
        <link href="https://artintellica.com/blog/0099-training-loop-14.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.4: Visualizing the Loss Landscape]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.3: Batch vs. Stochastic Gradient Descent]]></title>
        <id>https://artintellica.com/blog/0098-training-loop-13.md</id>
        <link href="https://artintellica.com/blog/0098-training-loop-13.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.3: Batch vs. Stochastic Gradient Descent]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.2: The Simplest Case: Linear Regression]]></title>
        <id>https://artintellica.com/blog/0097-training-loop-12.md</id>
        <link href="https://artintellica.com/blog/0097-training-loop-12.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.2: The Simplest Case: Linear Regression]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.1: Introduction to the Training Loop and Linear Regression]]></title>
        <id>https://artintellica.com/blog/0096-training-loop-11.md</id>
        <link href="https://artintellica.com/blog/0096-training-loop-11.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.1: Introduction to the Training Loop and Linear Regression]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch: Conclusion and the Road Ahead]]></title>
        <id>https://artintellica.com/blog/0095-rl-torch-conclusion.md</id>
        <link href="https://artintellica.com/blog/0095-rl-torch-conclusion.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch: Conclusion and the Road Ahead]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.4: Extensions—Double DQN and Dueling DQN]]></title>
        <id>https://artintellica.com/blog/0094-rl-torch-54-extensions.md</id>
        <link href="https://artintellica.com/blog/0094-rl-torch-54-extensions.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.4: Extensions—Double DQN and Dueling DQN]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.3: Experience Replay and Target Networks]]></title>
        <id>https://artintellica.com/blog/0093-rl-torch-53-experience.md</id>
        <link href="https://artintellica.com/blog/0093-rl-torch-53-experience.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.3: Experience Replay and Target Networks]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.2: Deep Q-Networks (DQN): Concepts and PyTorch Implementation]]></title>
        <id>https://artintellica.com/blog/0092-rl-torch-52-deep-q.md</id>
        <link href="https://artintellica.com/blog/0092-rl-torch-52-deep-q.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.2: Deep Q-Networks (DQN): Concepts and PyTorch Implementation]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.1: Limitations of Tabular RL and the Need for Function Approximation]]></title>
        <id>https://artintellica.com/blog/0091-rl-torch-51-limitations.md</id>
        <link href="https://artintellica.com/blog/0091-rl-torch-51-limitations.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.1: Limitations of Tabular RL and the Need for Function Approximation]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.7: Mini-Project—RL Agent on Custom Gridworld]]></title>
        <id>https://artintellica.com/blog/0090-rl-torch-47-project.md</id>
        <link href="https://artintellica.com/blog/0090-rl-torch-47-project.md"/>
        <updated>2025-06-14T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.7: Mini-Project—RL Agent on Custom Gridworld]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.6: Policies, Value Functions, and Bellman Equations]]></title>
        <id>https://artintellica.com/blog/0089-rl-torch-46-policies.md</id>
        <link href="https://artintellica.com/blog/0089-rl-torch-46-policies.md"/>
        <updated>2025-06-14T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.6: Policies, Value Functions, and Bellman Equations]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.5: Monte Carlo and Temporal Difference (TD) Learning]]></title>
        <id>https://artintellica.com/blog/0088-rl-torch-45-monte-carlo.md</id>
        <link href="https://artintellica.com/blog/0088-rl-torch-45-monte-carlo.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.5: Monte Carlo and Temporal Difference (TD) Learning]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.4: Tabular Value-Based Methods—Q-Learning and SARSA]]></title>
        <id>https://artintellica.com/blog/0087-rl-torch-44-tabular.md</id>
        <link href="https://artintellica.com/blog/0087-rl-torch-44-tabular.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.4: Tabular Value-Based Methods—Q-Learning and SARSA]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.3: Bandit Problems—Exploration vs. Exploitation]]></title>
        <id>https://artintellica.com/blog/0086-rl-torch-43-bandit.md</id>
        <link href="https://artintellica.com/blog/0086-rl-torch-43-bandit.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.3: Bandit Problems—Exploration vs. Exploitation]]></summary>
    </entry>
</feed>