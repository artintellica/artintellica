<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://artintellica.com/blog</id>
    <title>Artintellica Blog</title>
    <updated>2025-06-15T14:08:13.623Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <author>
        <name>Ryan X. Charles</name>
        <email>artintellica@ryanxcharles.com</email>
        <uri>https://artintellica.com</uri>
    </author>
    <link rel="alternate" href="https://artintellica.com/blog"/>
    <link rel="self" href="https://example.com/blog/feed.atom.xml"/>
    <subtitle>Artintellica Blog</subtitle>
    <icon>https://artintellica.com/favicon.ico</icon>
    <rights>Copyright (C) 2025 Ryan X. Charles</rights>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.1: Limitations of Tabular RL and the Need for Function Approximation]]></title>
        <id>https://artintellica.com/blog/0091-rl-torch-51-limitations.md</id>
        <link href="https://artintellica.com/blog/0091-rl-torch-51-limitations.md"/>
        <updated>2024-06-14T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.1: Limitations of Tabular RL and the Need for Function Approximation]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.7: Mini-Project—RL Agent on Custom Gridworld]]></title>
        <id>https://artintellica.com/blog/0090-rl-torch-47-project.md</id>
        <link href="https://artintellica.com/blog/0090-rl-torch-47-project.md"/>
        <updated>2024-06-14T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.7: Mini-Project—RL Agent on Custom Gridworld]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.6: Policies, Value Functions, and Bellman Equations]]></title>
        <id>https://artintellica.com/blog/0089-rl-torch-46-policies.md</id>
        <link href="https://artintellica.com/blog/0089-rl-torch-46-policies.md"/>
        <updated>2024-06-14T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.6: Policies, Value Functions, and Bellman Equations]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.5: Monte Carlo and Temporal Difference (TD) Learning]]></title>
        <id>https://artintellica.com/blog/0088-rl-torch-45-monte-carlo.md</id>
        <link href="https://artintellica.com/blog/0088-rl-torch-45-monte-carlo.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.5: Monte Carlo and Temporal Difference (TD) Learning]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.4: Tabular Value-Based Methods—Q-Learning and SARSA]]></title>
        <id>https://artintellica.com/blog/0087-rl-torch-44-tabular.md</id>
        <link href="https://artintellica.com/blog/0087-rl-torch-44-tabular.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.4: Tabular Value-Based Methods—Q-Learning and SARSA]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.3: Bandit Problems—Exploration vs. Exploitation]]></title>
        <id>https://artintellica.com/blog/0086-rl-torch-43-bandit.md</id>
        <link href="https://artintellica.com/blog/0086-rl-torch-43-bandit.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.3: Bandit Problems—Exploration vs. Exploitation]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.2: Markov Decision Processes—States, Actions, Rewards, Policies]]></title>
        <id>https://artintellica.com/blog/0085-rl-torch-42-markov.md</id>
        <link href="https://artintellica.com/blog/0085-rl-torch-42-markov.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.2: Markov Decision Processes—States, Actions, Rewards, Policies]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.1: What is Reinforcement Learning? RL vs. Supervised/Unsupervised]]></title>
        <id>https://artintellica.com/blog/0084-rl-torch-41-rl.md</id>
        <link href="https://artintellica.com/blog/0084-rl-torch-41-rl.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.1: What is Reinforcement Learning? RL vs. Supervised/Unsupervised]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.8: Mini-Project—MNIST Digit Classifier (Shallow NN)]]></title>
        <id>https://artintellica.com/blog/0083-rl-torch-38-project.md</id>
        <link href="https://artintellica.com/blog/0083-rl-torch-38-project.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.8: Mini-Project—MNIST Digit Classifier (Shallow NN)]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.7: Dropout, L2, and Other Regularization in PyTorch]]></title>
        <id>https://artintellica.com/blog/0082-rl-torch-37-dropout.md</id>
        <link href="https://artintellica.com/blog/0082-rl-torch-37-dropout.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.7: Dropout, L2, and Other Regularization in PyTorch]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.6: Overfitting, Underfitting, and Regularization]]></title>
        <id>https://artintellica.com/blog/0081-rl-torch-36-overfitting.md</id>
        <link href="https://artintellica.com/blog/0081-rl-torch-36-overfitting.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.6: Overfitting, Underfitting, and Regularization]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.5: Backpropagation—Intuition and Hands-On Example]]></title>
        <id>https://artintellica.com/blog/0080-rl-torch-35-backpropagation.md</id>
        <link href="https://artintellica.com/blog/0080-rl-torch-35-backpropagation.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.5: Backpropagation—Intuition and Hands-On Example]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.4: Activation Functions—Sigmoid, Tanh, ReLU, LeakyReLU, etc.]]></title>
        <id>https://artintellica.com/blog/0079-rl-torch-34-activation.md</id>
        <link href="https://artintellica.com/blog/0079-rl-torch-34-activation.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.4: Activation Functions—Sigmoid, Tanh, ReLU, LeakyReLU, etc.]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.3: Building with torch.nn—The Convenient Way]]></title>
        <id>https://artintellica.com/blog/0078-rl-torch-33-torch-nn.md</id>
        <link href="https://artintellica.com/blog/0078-rl-torch-33-torch-nn.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.3: Building with torch.nn—The Convenient Way]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.2: Feedforward Neural Networks from Scratch (No nn.Module)]]></title>
        <id>https://artintellica.com/blog/0077-rl-torch-32-feedforward.md</id>
        <link href="https://artintellica.com/blog/0077-rl-torch-32-feedforward.md"/>
        <updated>2024-06-11T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.2: Feedforward Neural Networks from Scratch (No nn.Module)]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.1: The Perceptron—Oldest Neural Network]]></title>
        <id>https://artintellica.com/blog/0076-rl-torch-31-perceptron.md</id>
        <link href="https://artintellica.com/blog/0076-rl-torch-31-perceptron.md"/>
        <updated>2024-06-11T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.1: The Perceptron—Oldest Neural Network]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.8: Mini-Project—Build, Train, and Visualize a Simple Classifier]]></title>
        <id>https://artintellica.com/blog/0075-rl-torch-28-project.md</id>
        <link href="https://artintellica.com/blog/0075-rl-torch-28-project.md"/>
        <updated>2024-06-11T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.8: Mini-Project—Build, Train, and Visualize a Simple Classifier]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.7: Softmax and Multiclass Classification]]></title>
        <id>https://artintellica.com/blog/0074-rl-torch-27-softmax.md</id>
        <link href="https://artintellica.com/blog/0074-rl-torch-27-softmax.md"/>
        <updated>2024-06-11T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.7: Softmax and Multiclass Classification]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.6: Classification Basics—Logistic Regression]]></title>
        <id>https://artintellica.com/blog/0073-rl-torch-26-classification.md</id>
        <link href="https://artintellica.com/blog/0073-rl-torch-26-classification.md"/>
        <updated>2024-06-11T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.6: Classification Basics—Logistic Regression]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.5: Fitting Nonlinear Curves—Polynomial Regression]]></title>
        <id>https://artintellica.com/blog/0072-rl-torch-25-nonlinear.md</id>
        <link href="https://artintellica.com/blog/0072-rl-torch-25-nonlinear.md"/>
        <updated>2024-06-10T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 2.5: Fitting Nonlinear Curves—Polynomial Regression]]></summary>
    </entry>
</feed>