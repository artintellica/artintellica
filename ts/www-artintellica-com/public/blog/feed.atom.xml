<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://artintellica.com/blog</id>
    <title>Artintellica Blog</title>
    <updated>2025-06-15T21:23:38.893Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <author>
        <name>Ryan X. Charles</name>
        <email>artintellica@ryanxcharles.com</email>
        <uri>https://artintellica.com</uri>
    </author>
    <link rel="alternate" href="https://artintellica.com/blog"/>
    <link rel="self" href="https://example.com/blog/feed.atom.xml"/>
    <subtitle>Artintellica Blog</subtitle>
    <icon>https://artintellica.com/favicon.ico</icon>
    <rights>Copyright (C) 2025 Ryan X. Charles</rights>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.3: Batch vs. Stochastic Gradient Descent]]></title>
        <id>https://artintellica.com/blog/0098-training-loop-13.md</id>
        <link href="https://artintellica.com/blog/0098-training-loop-13.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.3: Batch vs. Stochastic Gradient Descent]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.2: The Simplest Case: Linear Regression]]></title>
        <id>https://artintellica.com/blog/0097-training-loop-12.md</id>
        <link href="https://artintellica.com/blog/0097-training-loop-12.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.2: The Simplest Case: Linear Regression]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.1: Introduction to the Training Loop and Linear Regression]]></title>
        <id>https://artintellica.com/blog/0096-training-loop-11.md</id>
        <link href="https://artintellica.com/blog/0096-training-loop-11.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn the Training Loop with PyTorch, Part 1.1: Introduction to the Training Loop and Linear Regression]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch: Conclusion and the Road Ahead]]></title>
        <id>https://artintellica.com/blog/0095-rl-torch-conclusion.md</id>
        <link href="https://artintellica.com/blog/0095-rl-torch-conclusion.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch: Conclusion and the Road Ahead]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.4: Extensions—Double DQN and Dueling DQN]]></title>
        <id>https://artintellica.com/blog/0094-rl-torch-54-extensions.md</id>
        <link href="https://artintellica.com/blog/0094-rl-torch-54-extensions.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.4: Extensions—Double DQN and Dueling DQN]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.3: Experience Replay and Target Networks]]></title>
        <id>https://artintellica.com/blog/0093-rl-torch-53-experience.md</id>
        <link href="https://artintellica.com/blog/0093-rl-torch-53-experience.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.3: Experience Replay and Target Networks]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.2: Deep Q-Networks (DQN): Concepts and PyTorch Implementation]]></title>
        <id>https://artintellica.com/blog/0092-rl-torch-52-deep-q.md</id>
        <link href="https://artintellica.com/blog/0092-rl-torch-52-deep-q.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.2: Deep Q-Networks (DQN): Concepts and PyTorch Implementation]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.1: Limitations of Tabular RL and the Need for Function Approximation]]></title>
        <id>https://artintellica.com/blog/0091-rl-torch-51-limitations.md</id>
        <link href="https://artintellica.com/blog/0091-rl-torch-51-limitations.md"/>
        <updated>2025-06-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 5.1: Limitations of Tabular RL and the Need for Function Approximation]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.7: Mini-Project—RL Agent on Custom Gridworld]]></title>
        <id>https://artintellica.com/blog/0090-rl-torch-47-project.md</id>
        <link href="https://artintellica.com/blog/0090-rl-torch-47-project.md"/>
        <updated>2025-06-14T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.7: Mini-Project—RL Agent on Custom Gridworld]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.6: Policies, Value Functions, and Bellman Equations]]></title>
        <id>https://artintellica.com/blog/0089-rl-torch-46-policies.md</id>
        <link href="https://artintellica.com/blog/0089-rl-torch-46-policies.md"/>
        <updated>2025-06-14T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.6: Policies, Value Functions, and Bellman Equations]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.5: Monte Carlo and Temporal Difference (TD) Learning]]></title>
        <id>https://artintellica.com/blog/0088-rl-torch-45-monte-carlo.md</id>
        <link href="https://artintellica.com/blog/0088-rl-torch-45-monte-carlo.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.5: Monte Carlo and Temporal Difference (TD) Learning]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.4: Tabular Value-Based Methods—Q-Learning and SARSA]]></title>
        <id>https://artintellica.com/blog/0087-rl-torch-44-tabular.md</id>
        <link href="https://artintellica.com/blog/0087-rl-torch-44-tabular.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.4: Tabular Value-Based Methods—Q-Learning and SARSA]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.3: Bandit Problems—Exploration vs. Exploitation]]></title>
        <id>https://artintellica.com/blog/0086-rl-torch-43-bandit.md</id>
        <link href="https://artintellica.com/blog/0086-rl-torch-43-bandit.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.3: Bandit Problems—Exploration vs. Exploitation]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.2: Markov Decision Processes—States, Actions, Rewards, Policies]]></title>
        <id>https://artintellica.com/blog/0085-rl-torch-42-markov.md</id>
        <link href="https://artintellica.com/blog/0085-rl-torch-42-markov.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.2: Markov Decision Processes—States, Actions, Rewards, Policies]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.1: What is Reinforcement Learning? RL vs. Supervised/Unsupervised]]></title>
        <id>https://artintellica.com/blog/0084-rl-torch-41-rl.md</id>
        <link href="https://artintellica.com/blog/0084-rl-torch-41-rl.md"/>
        <updated>2025-06-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 4.1: What is Reinforcement Learning? RL vs. Supervised/Unsupervised]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.8: Mini-Project—MNIST Digit Classifier (Shallow NN)]]></title>
        <id>https://artintellica.com/blog/0083-rl-torch-38-project.md</id>
        <link href="https://artintellica.com/blog/0083-rl-torch-38-project.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.8: Mini-Project—MNIST Digit Classifier (Shallow NN)]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.7: Dropout, L2, and Other Regularization in PyTorch]]></title>
        <id>https://artintellica.com/blog/0082-rl-torch-37-dropout.md</id>
        <link href="https://artintellica.com/blog/0082-rl-torch-37-dropout.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.7: Dropout, L2, and Other Regularization in PyTorch]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.6: Overfitting, Underfitting, and Regularization]]></title>
        <id>https://artintellica.com/blog/0081-rl-torch-36-overfitting.md</id>
        <link href="https://artintellica.com/blog/0081-rl-torch-36-overfitting.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.6: Overfitting, Underfitting, and Regularization]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.5: Backpropagation—Intuition and Hands-On Example]]></title>
        <id>https://artintellica.com/blog/0080-rl-torch-35-backpropagation.md</id>
        <link href="https://artintellica.com/blog/0080-rl-torch-35-backpropagation.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.5: Backpropagation—Intuition and Hands-On Example]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.4: Activation Functions—Sigmoid, Tanh, ReLU, LeakyReLU, etc.]]></title>
        <id>https://artintellica.com/blog/0079-rl-torch-34-activation.md</id>
        <link href="https://artintellica.com/blog/0079-rl-torch-34-activation.md"/>
        <updated>2024-06-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn Reinforcement Learning with PyTorch, Part 3.4: Activation Functions—Sigmoid, Tanh, ReLU, LeakyReLU, etc.]]></summary>
    </entry>
</feed>